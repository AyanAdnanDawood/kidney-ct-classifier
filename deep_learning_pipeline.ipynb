{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# PART 1: Upload & Prepare New Incoming Dataset\n",
        "# ============================================\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "\n",
        "print(\"üìÅ Upload your NEW DATASET ZIP file:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "zip_path = list(uploaded.keys())[0]\n",
        "\n",
        "# Extract folder\n",
        "extract_to = \"/content/new_data\"\n",
        "os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "print(\"‚úÖ ZIP extracted to:\", extract_to)\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# Validate dataset structure and detect class folders\n",
        "# ---------------------------------------------------\n",
        "def find_class_folders(path):\n",
        "    folders = []\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for d in dirs:\n",
        "            if len(os.listdir(os.path.join(root, d))) > 0:\n",
        "                folders.append(os.path.join(root, d))\n",
        "        break\n",
        "    return folders\n",
        "\n",
        "class_folders = find_class_folders(extract_to)\n",
        "print(\"üìÇ Detected class folders:\", class_folders)\n",
        "\n",
        "# Extract class names\n",
        "class_names = [os.path.basename(c) for c in class_folders]\n",
        "print(\"üß™ Detected classes:\", class_names)\n",
        "\n",
        "# Check if they match the original 4\n",
        "original_classes = ['Cyst', 'Normal', 'Stone', 'Tumor']\n",
        "\n",
        "if sorted(class_names) != sorted(original_classes):\n",
        "    print(\"‚ùå ERROR: Class mismatch!\")\n",
        "    print(\"Expected:\", original_classes)\n",
        "    print(\"Found:\", class_names)\n",
        "else:\n",
        "    print(\"‚úÖ Class names match original training data.\")\n",
        "\n",
        "# Count images per class\n",
        "image_counts = {}\n",
        "for cls in class_folders:\n",
        "    imgs = [f for f in os.listdir(cls) if f.lower().endswith(('.jpg','.png','.jpeg'))]\n",
        "    image_counts[os.path.basename(cls)] = len(imgs)\n",
        "\n",
        "print(\"\\nüìä Image distribution in NEW dataset:\")\n",
        "print(image_counts)\n",
        "\n",
        "# Simple bar plot\n",
        "plt.bar(image_counts.keys(), image_counts.values())\n",
        "plt.title(\"New Dataset Class Distribution\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7CLiwgS2H58z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# PART 2: DATA DRIFT DETECTION\n",
        "# ============================================\n",
        "\n",
        "from scipy.stats import ks_2samp\n",
        "import cv2\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1) Load OLD training dataset path\n",
        "OLD_DATA_PATH = \"/content/data/train\"\n",
        "\n",
        "# 2) Load NEW data path\n",
        "NEW_DATA_PATH = extract_to\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "def load_pixels(folder):\n",
        "    pixel_values = []\n",
        "    for cls in os.listdir(folder):\n",
        "        cls_path = os.path.join(folder, cls)\n",
        "        for img in os.listdir(cls_path):\n",
        "            if img.lower().endswith(('.png','.jpg','.jpeg')):\n",
        "                p = cv2.imread(os.path.join(cls_path, img), 0)\n",
        "                if p is not None:\n",
        "                    p = cv2.resize(p, IMG_SIZE)\n",
        "                    pixel_values.append(p.flatten())\n",
        "    return np.array(pixel_values)\n",
        "\n",
        "print(\"üì• Loading OLD dataset pixels...\")\n",
        "old_pixels = load_pixels(OLD_DATA_PATH)\n",
        "\n",
        "print(\"üì• Loading NEW dataset pixels...\")\n",
        "new_pixels = load_pixels(NEW_DATA_PATH)\n",
        "\n",
        "# ----------------------------\n",
        "# 1Ô∏è‚É£ KS Test on Pixel Values\n",
        "# ----------------------------\n",
        "print(\"üî¨ Running KS test...\")\n",
        "ks_stats = []\n",
        "for i in range(1000):  # sample 1000 random pixels\n",
        "    old_sample = old_pixels[:, i]\n",
        "    new_sample = new_pixels[:, i]\n",
        "    _, p = ks_2samp(old_sample, new_sample)\n",
        "    ks_stats.append(p)\n",
        "\n",
        "ks_pvalue = np.mean(ks_stats)\n",
        "print(\"üìå KS p-value =\", ks_pvalue)\n",
        "\n",
        "# Interpret KS\n",
        "pixel_drift = ks_pvalue < 0.05\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2Ô∏è‚É£ Embedding Drift using VGG16 (feature representations)\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "base = VGG16(weights=\"imagenet\", include_top=False, pooling='avg')\n",
        "embedder = Model(inputs=base.input, outputs=base.output)\n",
        "\n",
        "def get_embeddings(folder):\n",
        "    embs = []\n",
        "    for cls in os.listdir(folder):\n",
        "        cls_path = os.path.join(folder, cls)\n",
        "        for img in tqdm(os.listdir(cls_path)):\n",
        "            if img.lower().endswith(('.jpg','.png')):\n",
        "                p = cv2.imread(os.path.join(cls_path, img))\n",
        "                if p is not None:\n",
        "                    p = cv2.resize(p, IMG_SIZE)\n",
        "                    p = np.expand_dims(p/255.0, axis=0)\n",
        "                    e = embedder.predict(p, verbose=0)\n",
        "                    embs.append(e.flatten())\n",
        "    return np.array(embs)\n",
        "\n",
        "print(\"üì• Getting OLD embeddings...\")\n",
        "old_emb = get_embeddings(OLD_DATA_PATH)\n",
        "\n",
        "print(\"üì• Getting NEW embeddings...\")\n",
        "new_emb = get_embeddings(NEW_DATA_PATH)\n",
        "\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# Compute avg cosine distance\n",
        "distances = []\n",
        "for i in range(min(len(old_emb), len(new_emb))):\n",
        "    distances.append(cosine(old_emb[i], new_emb[i]))\n",
        "\n",
        "embedding_drift_score = np.mean(distances)\n",
        "print(\"üìå Embedding drift score:\", embedding_drift_score)\n",
        "\n",
        "embedding_drift = embedding_drift_score > 0.25  # threshold\n",
        "\n",
        "# -------------------------------------------\n",
        "# Decide if drift happened\n",
        "# -------------------------------------------\n",
        "if pixel_drift or embedding_drift:\n",
        "    print(\"\\nüö®üö® DATA DRIFT DETECTED üö®üö®\")\n",
        "else:\n",
        "    print(\"\\n‚úÖ No drift detected. Safe to continue training.\")\n"
      ],
      "metadata": {
        "id": "hw4DjwDmIECS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# PART 3: TRAIN MODELS AGAIN (Custom + VGG)\n",
        "# ============================================\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16, ResNet50\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "\n",
        "# -------------------------------------------\n",
        "# 1) Split NEW DATA into train/val/test again\n",
        "# -------------------------------------------\n",
        "DATASET_PATH = NEW_DATA_PATH\n",
        "BASE = \"/content/split_data\"\n",
        "for d in ['train','val','test']:\n",
        "    os.makedirs(os.path.join(BASE, d), exist_ok=True)\n",
        "    for cls in class_names:\n",
        "        os.makedirs(os.path.join(BASE, d, cls), exist_ok=True)\n",
        "\n",
        "train_ratio, val_ratio, test_ratio = 0.7, 0.15, 0.15\n",
        "\n",
        "for cls in class_names:\n",
        "    cls_folder = os.path.join(DATASET_PATH, cls)\n",
        "    imgs = [f for f in os.listdir(cls_folder) if f.lower().endswith(('.jpg','.png','.jpeg'))]\n",
        "\n",
        "    train_imgs, temp_imgs = train_test_split(imgs, test_size=(1-train_ratio))\n",
        "    val_imgs, test_imgs = train_test_split(temp_imgs, test_size=test_ratio/(val_ratio+test_ratio))\n",
        "\n",
        "    for img in train_imgs:\n",
        "        shutil.copy(os.path.join(cls_folder, img), os.path.join(BASE, 'train', cls))\n",
        "\n",
        "    for img in val_imgs:\n",
        "        shutil.copy(os.path.join(cls_folder, img), os.path.join(BASE, 'val', cls))\n",
        "\n",
        "    for img in test_imgs:\n",
        "        shutil.copy(os.path.join(cls_folder, img), os.path.join(BASE, 'test', cls))\n",
        "\n",
        "# -------------------------------------------\n",
        "# 2) Generators\n",
        "# -------------------------------------------\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_gen = datagen.flow_from_directory(os.path.join(BASE,'train'), target_size=(224,224),\n",
        "                                        batch_size=32, class_mode='categorical')\n",
        "\n",
        "val_gen = datagen.flow_from_directory(os.path.join(BASE,'val'), target_size=(224,224),\n",
        "                                      batch_size=32, class_mode='categorical')\n",
        "\n",
        "# -------------------------------------------\n",
        "# 3) Train models (short version)\n",
        "# -------------------------------------------\n",
        "\n",
        "# Custom CNN\n",
        "custom_cnn = Sequential([\n",
        "    Conv2D(32,(3,3),activation='relu',input_shape=(224,224,3)),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(64,(3,3),activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Flatten(),\n",
        "    Dense(256,activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(class_names),activation='softmax')\n",
        "])\n",
        "custom_cnn.compile(optimizer=Adam(1e-4),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "custom_cnn.fit(train_gen, validation_data=val_gen, epochs=10)\n",
        "custom_cnn.save(\"/content/custom_cnn_model.h5\")\n",
        "\n",
        "# VGG16\n",
        "base_vgg = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
        "base_vgg.trainable = False\n",
        "\n",
        "vgg = Sequential([\n",
        "    base_vgg,\n",
        "    Flatten(),\n",
        "    Dense(256,activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(class_names),activation='softmax')\n",
        "])\n",
        "vgg.compile(optimizer=Adam(1e-4),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "vgg.fit(train_gen, validation_data=val_gen, epochs=10)\n",
        "vgg.save(\"/content/vgg16_model.h5\")\n",
        "\n",
        "print(\" Training complete! Models saved.\")\n"
      ],
      "metadata": {
        "id": "ZLxLV-8EIG5_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}